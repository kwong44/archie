---
trigger: model_decision
description: 
globs: 
---
1. Introduction

"The Architect" V1 has successfully established a core loop for users to reframe their language through voice journaling. The V2 initiative aims to evolve the application from a functional tool into an empathetic, conversational companion. By integrating Text-to-Speech (TTS), enhancing the user experience with proactive nudges and celebrations, and providing deeper insights, we will increase user engagement, drive habit formation, and accelerate the user's journey toward self-mastery.

2. Goals

Primary Goal: Increase user retention and session frequency by making the app more interactive, rewarding, and conversational.

Secondary Goal: Deepen the user's journey of self-reflection and pattern recognition by leveraging AI for proactive, voiced-based interactions.

Business Goal: Enhance the value proposition of the Premium subscription to drive conversions.

3. User Personas

Maya: A user navigating a stressful period who feels her emotions are often overwhelming. She is looking for a tool that not only listens but also helps her understand and challenge her negative thought patterns in a gentle, accessible way.

4. Epic-Based Rollout Plan

This project will be broken down into sequential epics, each building on the last to deliver value incrementally.

Epic 1: Foundation & The "Aha!" Moment

Objective: To deliver the app's core value instantly during onboarding and establish the AI as a voiced companion.

Task 1.1: Implement Conversational Onboarding with TTS

Description: The AI Guide will verbally welcome the user and guide them through the initial setup screens.

Acceptance Criteria:

[ ] Upon opening the app for the first time (app/(auth)/index.tsx), a welcome audio message is played automatically.

[ ] On the principle selection screen (app/(onboarding)/principles.tsx), the instructions are delivered via voice.

[ ] The audio is generated by calling the synthesizeText method in lib/aiApiClient.ts.

[ ] The feature correctly uses the existing expo-av dependency for audio playback.

Task 1.2: Create a "First Reframe" Onboarding Step

Description: Introduce a new step in the onboarding flow where the user records a short thought and performs their first guided word transformation.

Acceptance Criteria:

[ ] A new screen exists between the principle selection and lexicon setup (app/(onboarding)/).

[ ] This screen reuses the voice recording logic from the main Workshop screen (app/(tabs)/index.tsx).

[ ] The user's speech is transcribed, and one potential reframe word is highlighted.

[ ] The user can tap the word to see it transform, delivering an immediate "Aha!" moment.

[ ] The OnboardingService is updated to handle this initial entry, potentially personalizing the subsequent lexicon setup.

Task 1.3: Animate the First Achievement

Description: After the "First Reframe," display a visually rewarding, animated screen for the "First Steps" achievement.

Acceptance Criteria:

[ ] A new, full-screen "Achievement Unlocked" component is created.

[ ] Completing the "First Reframe" task triggers this component.

[ ] The AchievementsService logic correctly awards the first_session or a new first_reframe achievement.

[ ] The animation is smooth and leverages react-native-reanimated.

Task 1.4: Design Full-Screen Milestone Celebrations

Description: Create immersive, full-screen animated celebrations for major achievements.

Acceptance Criteria:

[ ] A reusable "Milestone" screen or modal is created.

[ ] The AchievementsService is updated to trigger this screen upon unlocking significant achievements (e.g., streak_30, sessions_50).

[ ] The animation reflects the nature of the achievement (e.g., a crown animating for "Mindful Master").

[ ] The screen provides a clear call-to-action to continue the journey.

Epic 2: The Conversational Core Loop

Objective: To make the daily journaling practice a dynamic, two-way conversation that proactively engages the user.

Task 2.1: Implement Proactive Push Notifications

Description: Send intelligent, personalized notifications to nudge users to engage with the app.

Acceptance Criteria:

[ ] The app integrates with a push notification service (e.g., Expo Push Notifications).

[ ] Notification content is generated based on user data by calling the InsightsService.

[ ] Notifications are personalized (e.g., "I noticed you often reflect at this time," or "Ready to work on reframing 'anxious' again?").

[ ] Users can opt-in/out of these notifications in the settings screen (app/(tabs)/guide.tsx).

Task 2.2: Implement AI Voice Follow-up (Clarity Coach)

Description: After a user finishes speaking their journal entry, the AI Guide will respond with a voiced, insightful question to prompt deeper reflection.

Acceptance Criteria:

[ ] In app/reframe.tsx, after transcription is complete, the app sends the transcript to the AI backend.

[ ] The backend (archie-ai-backend/app/routers/ai_summary.py) generates a relevant follow-up question.

[ ] The frontend receives the text, sends it to the TTS endpoint (/api/speech/synthesize), and plays the resulting audio.

[ ] The user can then respond to this prompt, either with voice or text, creating a conversational loop.

Task 2.3: Add Rewarding Micro-Interactions

Description: Enhance the reframing process with subtle animations and sounds to make it feel more satisfying.

Acceptance Criteria:

[ ] In app/reframe.tsx, when a word is successfully reframed, a subtle visual effect (e.g., sparkle, pulse) is triggered.

[ ] An optional, satisfying sound effect accompanies the transformation.

[ ] The UI elements on the dashboard (app/(tabs)/dashboard.tsx) that track progress (e.g., Day Streak) animate when updated.